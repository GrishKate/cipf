{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rb5VSo4mNkVd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, Tensor\n",
    "from tqdm import tqdm\n",
    "from src.tools import load_dataset\n",
    "import numpy as np\n",
    "# import wandb\n",
    "from src.model import SongUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "inner_iters = 10000\n",
    "batch_size = 64\n",
    "vocab_size = 256\n",
    "T = 10\n",
    "\n",
    "IMG_SIZE = 32\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tools import load_dataset\n",
    "sampler3, test_sampler3, loader3, test_loader3 = load_dataset('MNIST-colored_3', './datasets/MNIST', img_size=IMG_SIZE, batch_size=batch_size, device=device)\n",
    "sampler2, test_sampler2, loader2, test_loader2 = load_dataset('MNIST-colored_2', './datasets/MNIST', img_size=IMG_SIZE, batch_size=batch_size, device=device)\n",
    "Y_sampler = sampler3\n",
    "X_sampler = sampler2\n",
    "\n",
    "def sampler_0(batch_size: int = 200, device: str = \"cpu\") -> Tensor:\n",
    "    x_end = X_sampler.sample(batch_size)\n",
    "    # x_end = x_end.view(batch_size, -1).mul(0.5).add(0.5).clip(0,1)*255\n",
    "    x_end = x_end.mul(0.5).add(0.5).clip(0,1)*(vocab_size-1)\n",
    "    return x_end.long()\n",
    "\n",
    "def sampler_1(batch_size: int = 200, device: str = \"cpu\") -> Tensor:\n",
    "    x_end = Y_sampler.sample(batch_size)\n",
    "    # x_end = x_end.view(batch_size, -1).mul(0.5).add(0.5).clip(0,1)*255\n",
    "    x_end = x_end.mul(0.5).add(0.5).clip(0,1)*(vocab_size-1)\n",
    "    return x_end.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denoiser params: 35445888\n"
     ]
    }
   ],
   "source": [
    "model_f = SongUNet(img_resolution=32, in_channels=3, out_channels=3, vocab_size=vocab_size, model_channels=96).to(device)\n",
    "optim_f = torch.optim.Adam(model_f.parameters(), lr=1e-3)\n",
    "\n",
    "model_b = SongUNet(img_resolution=32, in_channels=3, out_channels=3, vocab_size=vocab_size, model_channels=96).to(device)\n",
    "optim_b = torch.optim.Adam(model_b.parameters(), lr=1e-3)\n",
    "\n",
    "print('denoiser params:', np.sum([np.prod(p.shape) for p in model_f.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_f = torch.load('model_f.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_data(model, optim, type='f'):\n",
    "    # for iter in tqdm(range(inner_iters)):\n",
    "    for iter in range(inner_iters):\n",
    "        loss_sum = 0\n",
    "        for i in range(100):\n",
    "            t = torch.randint(low=1, high=T + 2, size=(batch_size,), device=device)\n",
    "            x_1 = sampler_1(batch_size).view(batch_size, -1)\n",
    "            x_0 = sampler_0(batch_size).view(batch_size, -1)\n",
    "            \n",
    "            if type=='f':\n",
    "                x_t = torch.where(torch.randint(low=1, high=T + 2, size=(batch_size, model.d), device=device) <  t[:, None], x_1, x_0)\n",
    "            else:\n",
    "                x_t = torch.where(torch.randint(low=1, high=T + 2, size=(batch_size, model.d), device=device) <  t[:, None], x_0, x_1)\n",
    "\n",
    "            x_t = x_t.view(x_1.shape[0], IMG_CHANNELS, IMG_SIZE, IMG_SIZE)\n",
    "            logits = model(x_t, t).flatten(start_dim=0, end_dim=-2)\n",
    "            if type=='f':\n",
    "                loss = F.cross_entropy(logits, x_0.flatten(start_dim=0, end_dim=-1)).mean()\n",
    "            else:\n",
    "                loss = F.cross_entropy(logits, x_1.flatten(start_dim=0, end_dim=-1)).mean()\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "        print('Loss:', loss_sum/100)\n",
    "        visualize(sampler_0, model_b, f'samples/b/{iter}.png')\n",
    "        torch.save(model, 'model_b.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(traj):\n",
    "    costs = 0\n",
    "    for i in range(len(traj)-1):\n",
    "        costs += (traj[i] != traj[i+1]).float().mean()\n",
    "    \n",
    "    return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(sampler, model, name='samples/test.png'):\n",
    "    N = 10\n",
    "\n",
    "    x_t = sampler(N)\n",
    "    x_0 = x_t\n",
    "    t = T\n",
    "    results = [(x_t, t)]\n",
    "    while t > 0:\n",
    "        p1 = torch.softmax(model(x_t, torch.ones(N).to(device) * t), dim=-1)\n",
    "        one_hot_x_t = nn.functional.one_hot(x_t, vocab_size).float()\n",
    "        u = (p1 - one_hot_x_t) / (t/(T+1))\n",
    "        x_t = torch.distributions.Categorical(probs=one_hot_x_t + u/(T+1)).sample()\n",
    "        t -= 1\n",
    "        results.append((x_t.long(), t))\n",
    "\n",
    "    x_1 = results[-1][0]\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(results), figsize=(15, 3), sharex=True, sharey=True)\n",
    "\n",
    "    for i, (x_t, t) in enumerate(results):\n",
    "        axes[i].imshow(x_t.permute(0,2,3,1)[0].detach().cpu())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(name)  # Saves as PNG\n",
    "    plt.close()\n",
    "    plt.show()\n",
    "    # print('OT cost:', cost(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize(sampler_1, model_f)\n",
    "visualize(sampler_0, model_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.8423010694980622\n",
      "Loss: 1.2587761580944061\n",
      "Loss: 1.2557554805278779\n",
      "Loss: 1.2291932821273803\n",
      "Loss: 1.1978793466091155\n",
      "Loss: 1.1772280895709992\n",
      "Loss: 1.1655239129066468\n",
      "Loss: 1.1583278834819795\n",
      "Loss: 1.1464900326728822\n",
      "Loss: 1.1333092415332795\n",
      "Loss: 1.1098909020423888\n",
      "Loss: 1.1062028431892394\n",
      "Loss: 1.0940423929691314\n",
      "Loss: 1.0789812970161439\n",
      "Loss: 1.0712604308128357\n",
      "Loss: 1.0636603343486786\n",
      "Loss: 1.0569869679212571\n",
      "Loss: 1.0478315889835357\n",
      "Loss: 1.0405235147476197\n",
      "Loss: 1.037598915696144\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-362213487ca5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_with_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-e71af882523b>\u001b[0m in \u001b[0;36mtrain_with_data\u001b[0;34m(model, optim, type)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/python/envs/google_colab_gpu_2024/lib/python3.10/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/python/envs/google_colab_gpu_2024/lib/python3.10/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/python/envs/google_colab_gpu_2024/lib/python3.10/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m             )\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/python/envs/google_colab_gpu_2024/lib/python3.10/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/python/envs/google_colab_gpu_2024/lib/python3.10/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/python/envs/google_colab_gpu_2024/lib/python3.10/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0mexp_avg_sq_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_max_exp_avg_sqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m                 \u001b[0mexp_avg_sq_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_exp_avg_sqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_div_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_with_data(model_b, optim_b, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = sampler_0(10)\n",
    "x_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x_start = model_f.sample_trajectory(x_0, prior)[-2]\n",
    "plt.imshow(x_0.to('cpu').permute(0,2,3,1)[0].numpy().clip(0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred_x_start.to('cpu').permute(0,2,3,1)[0].numpy().clip(0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x_start.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_model(x, model, batch_size):\n",
    "    with torch.no_grad():\n",
    "        t = 0.0\n",
    "        while t < 1 - 1e-3:\n",
    "            p1 = torch.softmax(model(x, torch.ones(batch_size).to(device) * t), dim=-1)\n",
    "            h = min(0.01, 1.0 - t)\n",
    "            one_hot_x_t = nn.functional.one_hot(x, vocab_size).float()\n",
    "            u = (p1 - one_hot_x_t) / (1.0 - t)\n",
    "            x = torch.distributions.Categorical(probs=one_hot_x_t + h * u).sample()\n",
    "            t += h\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "g8QtNgs1-PlE",
    "wW3VMmrK2t2d",
    "_7aH8D0H3IJT"
   ],
   "name": "scalable_CNF.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Google Colab Analog 2024 (PyTorch 2.5.1 + TensorFlow 2.18) [python-google_colab_gpu_2024]",
   "language": "python",
   "name": "conda-env-python-google_colab_gpu_2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
